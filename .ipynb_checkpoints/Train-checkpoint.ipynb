{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c07aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e62f396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5dec21efb145248ab5d0262a175984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# login into huggingface\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d104c07e",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67d54ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22477de3a824a5d9ff077bcd7552830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8895c5dd7b4a20a17bfeeeca4db7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98378ace71c64a1db90e582257a26061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6b5f35596f4cdfb0911c0a285317ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/27596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635124f4a47c4bfe95ae8ee829deebe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "songs = load_dataset(\"miscjose/genius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e46f265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['title', 'lyrics'],\n",
       "        num_rows: 3450\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['title', 'lyrics'],\n",
       "        num_rows: 27596\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'lyrics'],\n",
       "        num_rows: 3450\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe332584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ring the alarm\n",
      "\n",
      "\n",
      "Lyrics: Ring the alarm\n",
      "I've been through this too long\n",
      "But I'll be damned if I see another chick on your arm\n",
      "Don't you ring the alarm\n",
      "I've been through this too long\n",
      "But I'll be damned if I see another chick on your arm\n",
      "She gon' be rockin' chinchilla coats\n",
      "If I let you go\n",
      "Benz and the house off the coast\n",
      "If I let you go\n",
      "She gon' take everything I own\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "She gone rock them VVS stones\n",
      "If I let you go (Coupes)\n",
      "In the 'Bach carter rolls\n",
      "If I let you go\n",
      "She go profit everything I taught\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "Tell me how should I feel\n",
      "When I know what I know\n",
      "And my female intuition\n",
      "Telling me you a dog\n",
      "People told me 'bout the flames\n",
      "I couldn't see through the smoke\n",
      "When I need answers, accusations\n",
      "What you mean you gone choke?\n",
      "You can't stay, you gotta go\n",
      "Ain't no other chick spending ya dough\n",
      "This is taking a toll\n",
      "The way the story unfolds\n",
      "Not the picture perfect movie everyone would've saw\n",
      "She gon' be rockin' chinchilla coats\n",
      "If I let you go\n",
      "Benz and the house off the coast\n",
      "If I let you go\n",
      "She gon' take everything I own\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "She gone rock them VVS stones\n",
      "If I let you go (Coupes)\n",
      "In the 'Bach carter rolls\n",
      "If I let you go\n",
      "She go profit everything I taught\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "Ring the alarm\n",
      "I've been through this too long\n",
      "But I'll be damned if I see another chick on your arm\n",
      "Don't you ring the alarm\n",
      "I've been through this too long\n",
      "But I'll be damned if I see another chick on your arm\n",
      "Tell me how should I feel\n",
      "When you made me belong\n",
      "And the thought of you just touching her is what I hate most\n",
      "I don't want you, but I want it and I can't let it go\n",
      "To know you give it to her like you gave it to me, come on\n",
      "(Oh)\n",
      "He's so arrogant and bold (Oh)\n",
      "But she gon' love that shit, I know\n",
      "I done put in a call\n",
      "Time to ring the alarm\n",
      "'Cause you ain't never seen a fire like the one I'm gon' cause\n",
      "She gon' be rockin' chinchilla coats\n",
      "If I let you go\n",
      "Benz and the house off the coast\n",
      "If I let you go\n",
      "She gon' take everything I own\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "She gone rock them VVS stones\n",
      "If I let you go (Coupes)\n",
      "In the 'Bach carter rolls\n",
      "If I let you go\n",
      "She go profit everything I taught\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "How can you look at me\n",
      "And not see all the things that I kept only just for you?\n",
      "Why would you risk it, baby?\n",
      "Is that the price I that pay?\n",
      "But this is my show and I won't let you go\n",
      "All it's been paid for, and it's mine\n",
      "How could you look at me\n",
      "And not see all the things?\n",
      "(See all the things, see all the things)\n",
      "She gon' be rockin' chinchilla coats\n",
      "If I let you go\n",
      "Benz and the house off the coast\n",
      "If I let you go\n",
      "She gon' take everything I own\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n",
      "She gone rock them VVS stones\n",
      "If I let you go (Coupes)\n",
      "In the 'Bach carter rolls\n",
      "If I let you go\n",
      "She go profit everything I taught\n",
      "If I let you go\n",
      "I can't let you go\n",
      "Damned if I let you go\n"
     ]
    }
   ],
   "source": [
    "# looking at a training sample\n",
    "\n",
    "print('Title: {}'.format(songs['train'][0]['title']))\n",
    "print('\\n')\n",
    "print('Lyrics: {}'.format(songs['train'][0]['lyrics']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79fa5e5",
   "metadata": {},
   "source": [
    "# Creating Metric Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae03ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64041ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jose\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 5.896, 'rouge2': 2.412, 'rougeL': 5.819, 'rougeLsum': 5.865}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lead 3 Baseline (in this case first 3 lyrics)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "def get_baseline(dataset, metric):\n",
    "    summaries = ['\\n'.join(text.split('\\n')[:3]) for text in dataset[\"lyrics\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"title\"])\n",
    "\n",
    "score = get_baseline(songs[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn] * 100, 3)) for rn in rouge_names)\n",
    "\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8b533",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a99571d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6790b294bc46d687fa29fb14a11df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\anaconda3\\envs\\huggingface\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jose\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9e865ceaf4423bbc0d417e765dcbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5781a5f1a52e4eb2a0494d66bda6b64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b532146eb34589a7a7494704f65cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "C:\\Program Files\\anaconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# first load tokenizer\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211cf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs and Attention\n",
      "{'input_ids': [65801, 336, 3869, 714, 12554, 309, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "\n",
      "Tokenization Method\n",
      "['▁Wow', '▁I', '▁love', '▁this', '▁Song', '!', '</s>']\n",
      "\n",
      "\n",
      "Max Input Lenght: 1000000000000000019884624838656\n"
     ]
    }
   ],
   "source": [
    "# testing out the tokenizer\n",
    "\n",
    "print('IDs and Attention')\n",
    "inputs = tokenizer('Wow I love this Song!')\n",
    "print(inputs)\n",
    "\n",
    "# check tokenizer\n",
    "print('\\n')\n",
    "print('Tokenization Method')\n",
    "print(tokenizer.convert_ids_to_tokens(inputs.input_ids))\n",
    "print('\\n')\n",
    "# check max length of input\n",
    "print('Max Input Lenght: {}'.format(tokenizer.model_max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358b5b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de9c0f926204baf9832386a0157b6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1214cf858fd8400caa7fd3c513065cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160eb5cefe564005bd8d3b119d991437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify limit for input and output\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 10\n",
    "\n",
    "# define function to map to train,validation, and test datasets\n",
    "def preprocess_function(examples):\n",
    "    # feeding into tokenizer produces token ids and attention\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"lyrics\"], max_length=max_input_length, truncation=True,\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        examples[\"title\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "    \n",
    "    # added additional label feature\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "# map to each dataset\n",
    "tokenized_data = songs.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539403fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "\tDataset({\n",
      "    features: ['title', 'lyrics'],\n",
      "    num_rows: 27596\n",
      "})\n",
      "\n",
      "\n",
      "After:\n",
      "\tDataset({\n",
      "    features: ['title', 'lyrics', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 27596\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# example of change applied to all datasets\n",
    "\n",
    "print('Before:\\n\\t{}'.format(songs['train']))\n",
    "print('\\n')\n",
    "print('After:\\n\\t{}'.format(tokenized_data['train']))\n",
    "\n",
    "# 3 extra columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f58b9",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80fb9a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da54f759897f442483052639687b5722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a21d454c134023a7f1bd02911567c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "300176768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model \n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14202b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters and other arguments\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "num_train_epochs = 5 \n",
    "# show the training loss with every epoch\n",
    "logging_steps = len(tokenized_data[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-genius\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=4.0e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    # number of checkpoints to save\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    # generate summaries during evaluation\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e59866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define compute metrics function\n",
    "\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "   \n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # extract the scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 3) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "886fda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data collator for dynamic padding\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a0f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove original text columns (we already have them but tokenized)\n",
    "\n",
    "tokenized_data = tokenized_data.remove_columns(\n",
    "    songs[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7071be45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/miscjose/mt5-small-finetuned-genius into local empty directory.\n",
      "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/miscjose/mt5-small-finetuned-genius into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "# instantiate the trainer\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9539b728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\anaconda3\\envs\\huggingface\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='863' max='863' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [863/863 02:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14.329600</td>\n",
       "      <td>7.807046</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>0.558000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n",
      "WARNING:huggingface_hub.repository:Adding files tracked by Git LFS: ['tokenizer.json']. This may take a bit of time if the files are large.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=863, training_loss=14.325111340537132, metrics={'train_runtime': 167.6341, 'train_samples_per_second': 164.62, 'train_steps_per_second': 5.148, 'total_flos': 284987821670400.0, 'train_loss': 14.325111340537132, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12979bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 7.807045936584473,\n",
       " 'eval_rouge1': 0.557,\n",
       " 'eval_rouge2': 0.089,\n",
       " 'eval_rougeL': 0.557,\n",
       " 'eval_rougeLsum': 0.558,\n",
       " 'eval_runtime': 20.8945,\n",
       " 'eval_samples_per_second': 165.116,\n",
       " 'eval_steps_per_second': 5.169,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check metrics\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1173ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "WARNING:huggingface_hub.repository:Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "WARNING:huggingface_hub.repository:The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417ee0e032854c2db03d0584c43d1910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/miscjose/mt5-small-finetuned-genius\n",
      "   c368014..18912c4  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/miscjose/mt5-small-finetuned-genius\n",
      "   c368014..18912c4  main -> main\n",
      "\n",
      "To https://huggingface.co/miscjose/mt5-small-finetuned-genius\n",
      "   18912c4..c4f2b55  main -> main\n",
      "\n",
      "WARNING:huggingface_hub.repository:To https://huggingface.co/miscjose/mt5-small-finetuned-genius\n",
      "   18912c4..c4f2b55  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/miscjose/mt5-small-finetuned-genius/commit/18912c4861a4577d06c456799ad9a216fac886bd'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push model to hub\n",
    "\n",
    "trainer.push_to_hub(commit_message=\"Training complete\", tags=\"summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04be779",
   "metadata": {},
   "source": [
    "# Using the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94709231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14cb8bf2d884bbc8176228975baf800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/773 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89b543d47cc454d9ff22d891e519aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c13941a17154459a3eacab0975ce8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e024f558e9c446c79dd9ae10713ad04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/303 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7c5cb626424eabaaea5c9bf43d0e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bbfa6529014c8d9c1809c0810c428c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe4469ee8044925a77a2e0c0b324dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "hub_model_id = \"miscjose/mt5-small-finetuned-genius\"\n",
    "summarizer = pipeline(\"summarization\", model=hub_model_id)\n",
    "# or\n",
    "# summarizer = pipeline(\"summarization\", tokenizer=tokenizer, config=args, model=model, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2e2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run some examples with the test set \n",
    "def print_summary(idx):\n",
    "    lyrics = songs[\"test\"][idx][\"lyrics\"]\n",
    "    title = songs[\"test\"][idx][\"title\"]\n",
    "    summary = summarizer(songs[\"test\"][idx][\"lyrics\"])[0][\"summary_text\"]\n",
    "    print('Lyrics: {}\\n'.format(lyrics))\n",
    "    print('Title: {}\\n'.format(title))\n",
    "    print('Summary: {}\\n'.format(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efb88fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics: After all the shit we did\n",
      "You gon' make me have to tell somebody, make me tell somebody\n",
      "Plead the fifth\n",
      "But in my mind I wanna tell somebody, wanna tell somebody\n",
      "The way I hit it, ohhhh you gon' make me have to surf on that ocean\n",
      "I might drown in your body let it drip\n",
      "But you so bad I gotta tell somebody, gotta tell somebody\n",
      "Oh, oh, oh my my my\n",
      "You really blowing my mind\n",
      "Oh, oh, oh my my my\n",
      "I ain't wasting no time\n",
      "Tell her hop on that quick\n",
      "And shade, fuck it up\n",
      "Do your dance, run it back\n",
      "We been on one\n",
      "Fall Back\n",
      "I will not snitch\n",
      "Fuck it up, do your dance\n",
      "Turn around and baby run it back\n",
      "I wish I could tell somebody\n",
      "First off, no I ain't the type to go kiss and tell everything\n",
      "And I'm so drunk that if I try it I misspell everything\n",
      "And you so drunk that you dance to like everything that come on\n",
      "We been mixing up these feelings with Hennessy and Patron\n",
      "Now you feeling the wave and I'm 'bout to jump in the deep-end\n",
      "I know that you tryna escape, and be my little secret\n",
      "Oh, oh, oh my my my\n",
      "You really blowing my mind\n",
      "Oh, oh, oh my my my\n",
      "I ain't wasting no time\n",
      "Tell her hop on that quick\n",
      "And shade, fuck it up\n",
      "Do your dance, run it back\n",
      "We been on one\n",
      "Fall Back\n",
      "I will not snitch\n",
      "Fuck it up, do your dance\n",
      "Turn around and baby run it back\n",
      "I wish I could tell somebody\n",
      "After all the shit we did\n",
      "You gon' make me have to tell somebody, make me tell somebody\n",
      "Plead the fifth\n",
      "But in my mind I wanna tell somebody, wanna tell somebody\n",
      "The way I hit it, ohhhh you gon' make me have to surf on that ocean\n",
      "I might drown in your body let it drip\n",
      "But you so bad I gotta tell somebody, gotta tell somebody\n",
      "Oh, oh, oh my my my\n",
      "You really blowing my mind\n",
      "Oh, oh, oh my my my\n",
      "I ain't wasting no time\n",
      "Tell her hop on that quick\n",
      "And shade, fuck it up\n",
      "Do your dance, run it back\n",
      "We been on one\n",
      "Fall Back\n",
      "I will not snitch\n",
      "Fuck it up, do your dance\n",
      "Turn around and baby run it back\n",
      "I wish I could tell somebody\n",
      "I should tell somebody about you\n",
      "That body you showin' off, girl you should be proud to\n",
      "That outfit you got on, I'm tryna get you out boo\n",
      "So glad that I found you, let's dip\n",
      "You don't really need the bullshit around you\n",
      "Still something in the fifth\n",
      "Hope you ready for round two\n",
      "..\n",
      "..\n",
      "\n",
      "Title: tell somebody\n",
      "\n",
      "Summary: <extra_id_0> a a a a a a a a a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check one example\n",
    "print_summary(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09db04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:huggingface]",
   "language": "python",
   "name": "conda-env-huggingface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
